{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMa+E+j+KI6vhsNpwu0TY0U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpo3SshUyS6x","executionInfo":{"status":"ok","timestamp":1762414093160,"user_tz":480,"elapsed":640,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"78a76c92-f72c-42b4-aae8-b51668d5ec41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import os\n","import gc\n","\n","\n","from matplotlib import pyplot as plt\n","plt.style.use('seaborn-v0_8')\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["DATA_PATH = \"/content/drive/MyDrive/SU Works/CPSC_5305_Intro_to_DS/Rizvans Works/Saved Data/processed_data.parquet\""],"metadata":{"id":"rwVaH_pizHXf","executionInfo":{"status":"ok","timestamp":1762414093165,"user_tz":480,"elapsed":2,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = pd.read_parquet(DATA_PATH)"],"metadata":{"id":"3SWH6CsqzVrR","executionInfo":{"status":"ok","timestamp":1762414104459,"user_tz":480,"elapsed":10806,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"wk9cqsU1zZ99","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762414104521,"user_tz":480,"elapsed":45,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"42903672-965d-4b0d-fd6b-ab8fd52a81e8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 59181090 entries, 0 to 59181089\n","Data columns (total 31 columns):\n"," #   Column              Dtype         \n","---  ------              -----         \n"," 0   date                datetime64[ns]\n"," 1   wm_yr_wk            int16         \n"," 2   weekday             category      \n"," 3   wday                int8          \n"," 4   month               int8          \n"," 5   year                int16         \n"," 6   d                   category      \n"," 7   event_name_1        category      \n"," 8   event_type_1        category      \n"," 9   event_name_2        category      \n"," 10  event_type_2        category      \n"," 11  snap_CA             int8          \n"," 12  snap_TX             int8          \n"," 13  snap_WI             int8          \n"," 14  id                  category      \n"," 15  item_id             category      \n"," 16  dept_id             category      \n"," 17  cat_id              category      \n"," 18  store_id            category      \n"," 19  state_id            category      \n"," 20  sales_count         int16         \n"," 21  sell_price          float32       \n"," 22  day_of_week         int8          \n"," 23  week_of_year        int8          \n"," 24  is_weekend          int8          \n"," 25  sales_lag_28        float32       \n"," 26  sales_lag_30        float32       \n"," 27  sales_lag_120       float32       \n"," 28  sales_lag_365       float32       \n"," 29  price_change        float32       \n"," 30  price_vs_month_avg  float32       \n","dtypes: category(12), datetime64[ns](1), float32(7), int16(3), int8(8)\n","memory usage: 3.6 GB\n"]}]},{"cell_type":"code","source":["print(df.head().to_markdown())"],"metadata":{"id":"-P2QS55ezyTx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762414107107,"user_tz":480,"elapsed":23,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"6fc22b0c-bb15-40a8-84d3-837519814ce9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["|    | date                |   wm_yr_wk | weekday   |   wday |   month |   year | d   | event_name_1   | event_type_1   | event_name_2   | event_type_2   |   snap_CA |   snap_TX |   snap_WI | id                            | item_id       | dept_id   | cat_id   | store_id   | state_id   |   sales_count |   sell_price |   day_of_week |   week_of_year |   is_weekend |   sales_lag_28 |   sales_lag_30 |   sales_lag_120 |   sales_lag_365 |   price_change |   price_vs_month_avg |\n","|---:|:--------------------|-----------:|:----------|-------:|--------:|-------:|:----|:---------------|:---------------|:---------------|:---------------|----------:|----------:|----------:|:------------------------------|:--------------|:----------|:---------|:-----------|:-----------|--------------:|-------------:|--------------:|---------------:|-------------:|---------------:|---------------:|----------------:|----------------:|---------------:|---------------------:|\n","|  0 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_001_CA_1_evaluation | HOBBIES_1_001 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         9.58 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n","|  1 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_002_CA_1_evaluation | HOBBIES_1_002 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         3.97 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n","|  2 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_003_CA_1_evaluation | HOBBIES_1_003 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         2.97 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n","|  3 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_004_CA_1_evaluation | HOBBIES_1_004 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         4.34 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n","|  4 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_005_CA_1_evaluation | HOBBIES_1_005 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         2.98 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import os\n","import gc\n","\n","\n","from matplotlib import pyplot as plt\n","plt.style.use('seaborn-v0_8')\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Added missing imports here for completeness, though already in notebook state\n","from sklearn.metrics import mean_squared_error\n","import lightgbm as lgb\n","\n","\n","# -----------------------------------------------------\n","# 1. Subsample the Data\n","# We will use data from 2014 onwards for our process.\n","# This makes the computation manageable for a single run on a large dataset.\n","print(\"Subsampling data for model training...\")\n","df_model = df[df['date'] >= '2014-01-01'].copy()\n","\n","# Drop the original date column as it's not a direct feature for LGBM, and 'd' handles day info\n","df_model = df_model.drop(columns=['date'])\n","gc.collect()\n","\n","print(f\"Shape of data for model training: {df_model.shape}\")\n","\n","# Calculate n_items for split size from the subsampled dataframe\n","n_items = len(df_model['id'].cat.categories)\n","\n","\n","# -----------------------------------------------------\n","# 2. Define Features and Target\n","# -----------------------------------------------------\n","features = [\n","    'wday', 'month', 'year', 'd', 'event_name_1', 'event_type_1',\n","    'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI',\n","    'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'sell_price',\n","    'day_of_week', 'week_of_year', 'is_weekend', 'sales_lag_28',\n","    'sales_lag_30', 'sales_lag_120', 'sales_lag_365', 'price_change',\n","    'price_vs_month_avg'\n","]\n","\n","# 'd' is a category, so including it in categorical features for LightGBM\n","cat_feats = [\n","    'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n","    'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'd'\n","]\n","\n","target = 'sales_count'\n","\n","# Separate features (X) and target (y) from the subsampled data\n","X = df_model[features]\n","y = df_model[target]\n","\n","# Clean up df_model to save memory\n","del df_model\n","gc.collect()\n","\n","\n","# -----------------------------------------------------\n","# 3. Perform a single Train/Validation Split\n","# The user requested no cross-validation, just a simple run.\n","# We will use the last 28 days worth of data as the validation set.\n","# This is consistent with the 'test_size' logic from the previous CV setup.\n","\n","val_size = 28 * n_items # Number of rows for 28 days across all unique items\n","\n","# Ensure val_size is not negative or larger than the entire dataset\n","if val_size <= 0 or val_size >= len(X):\n","    print(f\"Warning: Calculated validation size ({val_size}) is problematic. Adjusting to 10% of total data for validation.\")\n","    val_size = max(1, int(len(X) * 0.1))\n","\n","# Split the data into training and validation sets\n","train_index = range(len(X) - val_size)\n","val_index = range(len(X) - val_size, len(X))\n","\n","X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n","y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n","\n","print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}\")\n","\n","\n","# -----------------------------------------------------\n","# 4. Train the LightGBM Model\n","# -----------------------------------------------------\n","print(\"\\nStarting LightGBM model training on a single split...\")\n","\n","# Use LightGBM's Dataset object for memory efficiency\n","train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_feats, free_raw_data=False)\n","val_data = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_feats, free_raw_data=False)\n","\n","# Define model parameters\n","params = {\n","    'objective': 'tweedie',\n","    'metric': 'rmse',\n","    'n_estimators': 1500,\n","    'learning_rate': 0.05,\n","    'seed': 42,\n","    'n_jobs': -1,\n","    'num_leaves': 128,\n","    'max_bin': 127,\n","    'boosting_type': 'gbdt',\n","    'verbose': -1,\n","}\n","\n","# Train the model\n","model = lgb.train(\n","    params,\n","    train_data,\n","    valid_sets=[val_data],\n","    callbacks=[lgb.early_stopping(50, verbose=False)],\n",")\n","\n","# -----------------------------------------------------\n","# 5. Report Validation Score\n","# -----------------------------------------------------\n","# Make predictions and calculate RMSE for this single run\n","preds = model.predict(X_val)\n","rmse = np.sqrt(mean_squared_error(y_val, preds))\n","\n","print(f\"\\nFinished single model training.\")\n","print(f\"Validation RMSE for the hold-out set: {rmse:.4f}\")\n","\n","# Clean up memory\n","del X_train, X_val, y_train, y_val, train_data, val_data, preds\n","gc.collect()\n"],"metadata":{"id":"1EaZm-pb1PJT","colab":{"base_uri":"https://localhost:8080/","height":495},"executionInfo":{"status":"error","timestamp":1762413585029,"user_tz":480,"elapsed":3315448,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"0b7233a1-0f03-4a1b-eae3-b1565b147504"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting Time Series Cross-Validation...\n","--- FOLD 1 ---\n","Train size: 56619930, Validation size: 853720\n","Fold 1 RMSE: 2.3497320608391883\n","\n","--- FOLD 2 ---\n","Train size: 57473650, Validation size: 853720\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1436718692.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     model = lgb.train(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4153\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot update due to null objective function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m             _safe_call(\n\u001b[0;32m-> 4155\u001b[0;31m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   4156\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4157\u001b[0m                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"gIg3BWuz0O9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"iPStzKgM5cpp","colab":{"base_uri":"https://localhost:8080/","height":210},"outputId":"3b360171-ded2-4ef7-b420-b65fbe7cffa4","executionInfo":{"status":"error","timestamp":1762414403085,"user_tz":480,"elapsed":2358,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3481037983.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m \u001b[0;31m# For memory management\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# --- Subsample the Data ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.linear_model import LogisticRegression, Ridge\n","from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, mean_squared_error\n","from sklearn.model_selection import TimeSeriesSplit # Not used directly in this version\n","import gc # For memory management\n","\n","df.dropna(inplace=True)\n","\n","# --- Subsample the Data ---\n","# To make Ridge Regression feasible on a large dataset, let's subsample.\n","# We will use data from 2014 onwards, similar to the LGBM model.\n","print(\"Subsampling data for Ridge Regression model training...\")\n","df_ridge = df[df['date'] >= '2014-01-01'].copy()\n","\n","# Drop the original date column as it's not a direct feature\n","df_ridge = df_ridge.drop(columns=['date'])\n","gc.collect()\n","\n","print(f\"Shape of subsampled data for Ridge Regression: {df_ridge.shape}\")\n","\n","\n","# Define feature columns (X) and target column (y)\n","target = 'sales_count'\n","categorical_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n","                        'weekday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n","numeric_features = ['wday', 'month', 'year',\n","                    'snap_CA', 'snap_TX', 'snap_WI',\n","                    'sell_price', 'day_of_week', 'week_of_year', 'is_weekend', 'sales_lag_28',\n","    'sales_lag_30', 'sales_lag_120', 'sales_lag_365', 'price_change',\n","    'price_vs_month_avg']\n","\n","# Combine all features\n","features = categorical_features + numeric_features\n","\n","X = df_ridge[features]\n","y = df_ridge[target]\n","\n","# Clean up df_ridge to save memory\n","del df_ridge\n","gc.collect()\n","\n","\n","# Create a preprocessor\n","# OneHotEncoder for categorical features\n","# 'passthrough' for numeric features\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n","        ('num', 'passthrough', numeric_features)\n","    ],\n","    remainder='drop'  # Drop any columns not specified\n",")\n","\n","# Create the model pipeline\n","model = Pipeline(steps=[('preprocessor', preprocessor),\n","                        ('regressor', Ridge(alpha=1.0, random_state=42))])\n","\n","# --- Train on the entire (subsampled) dataset ---\n","print(\"Training Ridge Regression model on the subsampled dataset...\")\n","print(\"Fitting pipeline...\")\n","model.fit(X, y)\n","\n","# Predict on the training data itself\n","print(\"Evaluating model on training data...\")\n","train_preds = model.predict(X)\n","\n","# Ensure predictions are non-negative\n","train_preds[train_preds < 0] = 0\n","\n","# Calculate RMSE on the training data\n","rmse = np.sqrt(mean_squared_error(y, train_preds))\n","print(f\"Training RMSE: {rmse:.4f}\")\n","\n","print(\"\\n--- Training Complete ---\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"YvKd3-wWCXTC"},"execution_count":null,"outputs":[]}]}