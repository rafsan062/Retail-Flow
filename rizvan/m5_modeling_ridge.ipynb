{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyO45laukNNbZI5sLUGhIvQe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpo3SshUyS6x","executionInfo":{"status":"ok","timestamp":1762414848185,"user_tz":480,"elapsed":18669,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"60428095-c9f7-4a32-c78c-d10d3e9b50c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import os\n","import gc\n","\n","\n","from matplotlib import pyplot as plt\n","plt.style.use('seaborn-v0_8')\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["DATA_PATH = \"/content/drive/MyDrive/SU Works/CPSC_5305_Intro_to_DS/Rizvans Works/Saved Data/processed_data.parquet\""],"metadata":{"id":"rwVaH_pizHXf","executionInfo":{"status":"ok","timestamp":1762414848186,"user_tz":480,"elapsed":0,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df = pd.read_parquet(DATA_PATH)"],"metadata":{"id":"3SWH6CsqzVrR","executionInfo":{"status":"ok","timestamp":1762414863049,"user_tz":480,"elapsed":14862,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"wk9cqsU1zZ99","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762414863107,"user_tz":480,"elapsed":54,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"385c4b94-d4a3-4221-d1ed-f3a7addb199c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 59181090 entries, 0 to 59181089\n","Data columns (total 31 columns):\n"," #   Column              Dtype         \n","---  ------              -----         \n"," 0   date                datetime64[ns]\n"," 1   wm_yr_wk            int16         \n"," 2   weekday             category      \n"," 3   wday                int8          \n"," 4   month               int8          \n"," 5   year                int16         \n"," 6   d                   category      \n"," 7   event_name_1        category      \n"," 8   event_type_1        category      \n"," 9   event_name_2        category      \n"," 10  event_type_2        category      \n"," 11  snap_CA             int8          \n"," 12  snap_TX             int8          \n"," 13  snap_WI             int8          \n"," 14  id                  category      \n"," 15  item_id             category      \n"," 16  dept_id             category      \n"," 17  cat_id              category      \n"," 18  store_id            category      \n"," 19  state_id            category      \n"," 20  sales_count         int16         \n"," 21  sell_price          float32       \n"," 22  day_of_week         int8          \n"," 23  week_of_year        int8          \n"," 24  is_weekend          int8          \n"," 25  sales_lag_28        float32       \n"," 26  sales_lag_30        float32       \n"," 27  sales_lag_120       float32       \n"," 28  sales_lag_365       float32       \n"," 29  price_change        float32       \n"," 30  price_vs_month_avg  float32       \n","dtypes: category(12), datetime64[ns](1), float32(7), int16(3), int8(8)\n","memory usage: 3.6 GB\n"]}]},{"cell_type":"code","source":["print(df.head().to_markdown())"],"metadata":{"id":"-P2QS55ezyTx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762414863147,"user_tz":480,"elapsed":38,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"cf8619bb-33dc-4d60-b8d9-1230d63c452c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["|    | date                |   wm_yr_wk | weekday   |   wday |   month |   year | d   | event_name_1   | event_type_1   | event_name_2   | event_type_2   |   snap_CA |   snap_TX |   snap_WI | id                            | item_id       | dept_id   | cat_id   | store_id   | state_id   |   sales_count |   sell_price |   day_of_week |   week_of_year |   is_weekend |   sales_lag_28 |   sales_lag_30 |   sales_lag_120 |   sales_lag_365 |   price_change |   price_vs_month_avg |\n","|---:|:--------------------|-----------:|:----------|-------:|--------:|-------:|:----|:---------------|:---------------|:---------------|:---------------|----------:|----------:|----------:|:------------------------------|:--------------|:----------|:---------|:-----------|:-----------|--------------:|-------------:|--------------:|---------------:|-------------:|---------------:|---------------:|----------------:|----------------:|---------------:|---------------------:|\n","|  0 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_001_CA_1_evaluation | HOBBIES_1_001 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         9.58 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n","|  1 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_002_CA_1_evaluation | HOBBIES_1_002 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         3.97 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n","|  2 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_003_CA_1_evaluation | HOBBIES_1_003 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         2.97 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n","|  3 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_004_CA_1_evaluation | HOBBIES_1_004 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         4.34 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n","|  4 | 2011-01-29 00:00:00 |      11101 | Saturday  |      1 |       1 |   2011 | d_1 | No Event       | No Event       | No Event       | No Event       |         0 |         0 |         0 | HOBBIES_1_005_CA_1_evaluation | HOBBIES_1_005 | HOBBIES_1 | HOBBIES  | CA_1       | CA         |             0 |         2.98 |             5 |              4 |            1 |              0 |              0 |               0 |               0 |              0 |                    1 |\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPStzKgM5cpp","colab":{"base_uri":"https://localhost:8080/","height":210},"outputId":"3b360171-ded2-4ef7-b420-b65fbe7cffa4","executionInfo":{"status":"error","timestamp":1762414403085,"user_tz":480,"elapsed":2358,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3481037983.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m \u001b[0;31m# For memory management\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# --- Subsample the Data ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.linear_model import LogisticRegression, Ridge\n","from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, mean_squared_error\n","from sklearn.model_selection import TimeSeriesSplit # Not used directly in this version\n","import gc # For memory management\n","\n","df.dropna(inplace=True)\n","\n","# --- Subsample the Data ---\n","# To make Ridge Regression feasible on a large dataset, let's subsample.\n","# We will use data from 2014 onwards, similar to the LGBM model.\n","print(\"Subsampling data for Ridge Regression model training...\")\n","df_ridge = df[df['date'] >= '2014-01-01'].copy()\n","\n","# Drop the original date column as it's not a direct feature\n","df_ridge = df_ridge.drop(columns=['date'])\n","gc.collect()\n","\n","print(f\"Shape of subsampled data for Ridge Regression: {df_ridge.shape}\")\n","\n","\n","# Define feature columns (X) and target column (y)\n","target = 'sales_count'\n","categorical_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n","                        'weekday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n","numeric_features = ['wday', 'month', 'year',\n","                    'snap_CA', 'snap_TX', 'snap_WI',\n","                    'sell_price', 'day_of_week', 'week_of_year', 'is_weekend', 'sales_lag_28',\n","    'sales_lag_30', 'sales_lag_120', 'sales_lag_365', 'price_change',\n","    'price_vs_month_avg']\n","\n","# Combine all features\n","features = categorical_features + numeric_features\n","\n","X = df_ridge[features]\n","y = df_ridge[target]\n","\n","# Clean up df_ridge to save memory\n","del df_ridge\n","gc.collect()\n","\n","\n","# Create a preprocessor\n","# OneHotEncoder for categorical features\n","# 'passthrough' for numeric features\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n","        ('num', 'passthrough', numeric_features)\n","    ],\n","    remainder='drop'  # Drop any columns not specified\n",")\n","\n","# Create the model pipeline\n","model = Pipeline(steps=[('preprocessor', preprocessor),\n","                        ('regressor', Ridge(alpha=1.0, random_state=42))])\n","\n","# --- Train on the entire (subsampled) dataset ---\n","print(\"Training Ridge Regression model on the subsampled dataset...\")\n","print(\"Fitting pipeline...\")\n","model.fit(X, y)\n","\n","# Predict on the training data itself\n","print(\"Evaluating model on training data...\")\n","train_preds = model.predict(X)\n","\n","# Ensure predictions are non-negative\n","train_preds[train_preds < 0] = 0\n","\n","# Calculate RMSE on the training data\n","rmse = np.sqrt(mean_squared_error(y, train_preds))\n","print(f\"Training RMSE: {rmse:.4f}\")\n","\n","print(\"\\n--- Training Complete ---\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"YvKd3-wWCXTC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"71bf27d7"},"source":["# Task\n","Refactor the existing Ridge Regression model to utilize Dask-ML for parallel and distributed computation. This involves initializing a Dask client, converting the subsampled pandas DataFrame to a Dask DataFrame, replacing scikit-learn components with their Dask-ML equivalents (`dask_ml.preprocessing.ColumnTransformer` and `dask_ml.linear_model.Ridge`), and then training and evaluating the Dask-ML pipeline, ensuring non-negative predictions."]},{"cell_type":"markdown","metadata":{"id":"a6c8674c"},"source":["## Set up Dask\n","\n","### Subtask:\n","Initialize a Dask client to enable parallel and distributed computation.\n"]},{"cell_type":"markdown","metadata":{"id":"49f61b30"},"source":["**Reasoning**:\n","To initialize a Dask client, I need to first import the `Client` class from `dask.distributed` and then create an instance of it.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57feaef9","executionInfo":{"status":"ok","timestamp":1762415163260,"user_tz":480,"elapsed":3424,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"c0f79340-4f3e-4f2b-d236-6ce517f0b342"},"source":["from dask.distributed import Client\n","\n","client = Client() # Creates a local Dask client\n","print(client)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n","INFO:distributed.scheduler:State start\n","INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:39637\n","INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n","INFO:distributed.scheduler:Registering Worker plugin shuffle\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:34797'\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:43133'\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:43951'\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:37863'\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:45679 name: 1\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:45679\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:45388\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:42557 name: 0\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:42557\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:45396\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:35213 name: 3\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:35213\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:45412\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:34667 name: 2\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:34667\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:45422\n","INFO:distributed.scheduler:Receive client connection: Client-a4106b73-bae4-11f0-9752-0242ac1c000c\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:45432\n"]},{"output_type":"stream","name":"stdout","text":["<Client: 'tcp://127.0.0.1:39637' processes=4 threads=8, memory=50.99 GiB>\n"]}]},{"cell_type":"markdown","metadata":{"id":"c1456c4b"},"source":["**Reasoning**:\n","The previous cell resulted in a `NameError` because `df` was not defined. I need to re-load `df`, apply `dropna`, subsample it as `df_ridge`, extract `X` and `y` from this subsampled DataFrame, and then convert `X` and `y` into Dask DataFrames and Dask Array, respectively, as part of preparing the data for Dask-ML.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c39b68cd","executionInfo":{"status":"ok","timestamp":1762415199031,"user_tz":480,"elapsed":19829,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"65251419-397d-4021-cc4f-9c2fc6abb63e"},"source":["import numpy as np\n","import pandas as pd\n","import dask.dataframe as dd\n","import dask.array as da\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder # Keep sklearn for ColumnTransformer structure, though dask_ml will replace it later\n","from sklearn.linear_model import LogisticRegression, Ridge\n","from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, mean_squared_error\n","import gc # For memory management\n","\n","# DATA_PATH should be defined from earlier cell\n","# df should be loaded from earlier cell\n","\n","# Re-load df and process it as it was lost in the previous execution state\n","df = pd.read_parquet(DATA_PATH)\n","\n","df.dropna(inplace=True)\n","\n","print(\"Subsampling data for Ridge Regression model training...\")\n","df_ridge = df[df['date'] >= '2014-01-01'].copy()\n","\n","# Drop the original date column as it's not a direct feature\n","df_ridge = df_ridge.drop(columns=['date'])\n","gc.collect()\n","\n","print(f\"Shape of subsampled data for Ridge Regression: {df_ridge.shape}\")\n","\n","\n","# Define feature columns (X) and target column (y)\n","target = 'sales_count'\n","categorical_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n","                        'weekday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n","numeric_features = ['wday', 'month', 'year',\n","                    'snap_CA', 'snap_TX', 'snap_WI',\n","                    'sell_price', 'day_of_week', 'week_of_year', 'is_weekend', 'sales_lag_28',\n","    'sales_lag_30', 'sales_lag_120', 'sales_lag_365', 'price_change',\n","    'price_vs_month_avg']\n","\n","# Combine all features\n","features = categorical_features + numeric_features\n","\n","# Extract X and y as pandas DataFrames/Series first\n","X_pandas = df_ridge[features]\n","y_pandas = df_ridge[target]\n","\n","# Clean up df_ridge to save memory\n","del df_ridge\n","del df\n","gc.collect()\n","\n","# Convert pandas DataFrames to Dask DataFrames/Arrays\n","print(\"Converting pandas DataFrames to Dask DataFrames...\")\n","X = dd.from_pandas(X_pandas, npartitions=4) # Adjust npartitions based on your cluster and data size\n","y = da.from_array(y_pandas.values, chunks=y_pandas.shape[0] // 4) # Adjust chunks for Dask Array\n","\n","print(f\"Shape of Dask X: {X.shape}, type: {type(X)}\")\n","print(f\"Shape of Dask y: {y.shape}, type: {type(y)}\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Subsampling data for Ridge Regression model training...\n","Shape of subsampled data for Ridge Regression: (26617770, 30)\n","Converting pandas DataFrames to Dask DataFrames...\n","Shape of Dask X: (<dask_expr.expr.Scalar: expr=df.size() // 26, dtype=int64>, 26), type: <class 'dask.dataframe.dask_expr._collection.DataFrame'>\n","Shape of Dask y: (26617770,), type: <class 'dask.array.core.Array'>\n"]}]},{"cell_type":"markdown","metadata":{"id":"f2014614"},"source":["**Reasoning**:\n","Now that the data is prepared as Dask DataFrames/Arrays, I need to replace the scikit-learn components (`ColumnTransformer`, `OneHotEncoder`, `Ridge`) with their Dask-ML equivalents to build a Dask-compatible preprocessing pipeline and model.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"cdb3e031","executionInfo":{"status":"error","timestamp":1762415209906,"user_tz":480,"elapsed":13,"user":{"displayName":"Rizvan Ahmed Rafsan","userId":"03520658315208929984"}},"outputId":"37d974f3-ca4e-4e06-d041-1aa51ae66cd1"},"source":["import dask_ml.preprocessing as dm_preproc\n","import dask_ml.linear_model as dm_linear_model\n","from dask_ml.compose import ColumnTransformer as DaskColumnTransformer\n","from dask_ml.model_selection import KFold # Placeholder, not used for training, but good to import if needed for CV later\n","\n","# Create a Dask-ML preprocessor\n","# OneHotEncoder for categorical features\n","# 'passthrough' for numeric features\n","preprocessor_dask = DaskColumnTransformer(\n","    transformers=[\n","        ('cat', dm_preproc.OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n","        ('num', 'passthrough', numeric_features)\n","    ],\n","    remainder='drop'  # Drop any columns not specified\n",")\n","\n","# Create the Dask-ML model pipeline\n","model_dask = Pipeline(steps=[('preprocessor', preprocessor_dask),\n","                            ('regressor', dm_linear_model.Ridge(alpha=1.0, random_state=42))])\n","\n","print(\"Dask-ML pipeline created successfully.\")"],"execution_count":8,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'dask_ml'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-130050685.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdask_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdm_preproc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdask_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdm_linear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColumnTransformer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDaskColumnTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m \u001b[0;31m# Placeholder, not used for training, but good to import if needed for CV later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask_ml'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","metadata":{"id":"bfab4670"},"source":["**Reasoning**:\n","The previous cell failed because the `dask_ml` library was not found. I need to install `dask-ml` using `pip` before attempting to import its modules.\n","\n"]}]}